---
title: "Thoughts on creative action and measurement systems"
author: "Brad Venner"
date: "5/13/2025"
output: html_document
---

Mari develops the duality between a "measurement procedure" and a "measurement process". A "measurement procedure", or method, is the "plan of action" while the "measurement process" is the action itself. 

Was looking at Joas' book *Social Theory: Twenty Introductory Lectures* [@joas:2009:social], particularly Chapter 19 *Neo-pragmatism*, where Joas outlines his theory of creative action. He develops the idea that goals of action have a reciprocal relationship with the means of action.

> the goals of action are usually relatively undefined, and only become more specific as a consequence of the decision to use particular means. Reciprocity of goals and means therefore signifies the interaction of the choice of means and the definition of goals. The dimension of means in relation to the dimension of goals is in no way neutral. Only when we recognize that certain means are available to us do we discover goals which had not occurred to us before. [@joas:1996:creativity, p. 154]

This passage reminded me of this duality in measurement, so that there is a "reciprocity" between procedure and process.

I don't know enough systems theory yet, but there seems to be a parallel distinction between "requirements" and "system". There is a notion of validation in which it is demonstrated that a realized system satisfies its requirements. The notion of method/procedure validation draws upon a similar distinction, where specified requirements are developed and experiments are performed to demonstrate that the realized system (aka the measurement process) meets the requirements.  

A similar duality in ISO 17025 is between "method" and "results". Both are subject to "validation". One way to understand this is as a specialization of the procedure/process duality, but this doesn't really work as the notion of "method validation" must already draw upon a realized process in order to validate the method.

I've advocated in my lab training that the notion of "validation of results" should relate to the concept of the scope of the method. This is an explicity parallel construction with the Federal Rules of Evidence, where it must be shown that:

> \(c\) the testimony is the product of reliable principles and methods; 

and

> \(d\) the expert's opinion reflects a reliable application of the principles and methods to the facts of the case. (Rule 702)

Clause \(c\) is the method, while clause \(d\) is the result.

ISO 17025 seems to understand "validation of results" as the more common idea of quality control, where the measuring system is monitored to ensure that it is "in control". This model neglects the "incoming variety" and assumes that the sole source of uncertainty is the measuring system. This could be identified within the distinction between statistical process control and cybernetics. I believe that Seddon also distinguishes services from manufacturing in this way, that services must respond to a wider variety than manufacturing. Manufacturing can have greater control on it's inputs than a service.   

Mari draws the distinction between the "intended property" as measurand and the "effective property" as the actual relationship between the measuring instrument and the "system under measurement". This is a distinction between goals and means. Mari develops several examples of how the gap between the the "intended" and "effective" properties. 

Seddon's article on *Rethinking Regulation* may have some applicability to this problem. Seddon distinguishes between purpose, measures and methods. 

> For an understanding of real performance, measures must be related to purpose, thereby directing manager's attention to devising better methods for improving those measures and better satisfying the organization's purpose.

Method validation guidance recommends deriving "performance characteristics" of an analytical procedure from the purpose of measurement. Seddon would call this a "method", but this conflicts with "analytical method". It's a higher-level control or a meta-method. Could be "validation method" for an "analytical procedure".

Seddon's examples focus on direct service provision by government agencies. This makes sense as he's taken his analysis of service provision in the private sector and applied it directly to public sector agencies. The understanding neglects the "imposing duties" understanding of public-sector regulation by Malcom Sparrow, which arose out of his work in policing \(public safety \). In this conception, the subjects and beneficiaries of public-sector regulation are different. This separation is consistent with Dewey's understanding of the public, which arises in response to the understanding of a common interest due to adverse effects of 'private-sector' actors \(although Dewey does not use this term\). In Seddon's work, there is a distinction between a manager and a provider, and he seems to assume that this distinction carries over to "risk control".

Note that Sparrow has several books that I have not read, including *Imposing Duties*, *The Character of Harms*, and *Fundamentals of Regulatory Design*. All of these would be worth reading!