---
title: "Revisiting categorical semiotics"
author: "Brad Venner"
date: "3/26/2024"
output: html_document
---

# Introduction

Can my previous study of semiotics help with understanding/developing/using "cognitive language agents"?

If so, what is the appropriate role? 

Some subproblems are:

1. What can the doctrine of semiotics contribute to cognitive science? This problem has been considered under the term "cognitive semiotics"

2. Is the study of human cognition in cognitive science helpful in the development of artificial cognitive agents, i.e. *cognitive engineering". This problem has been considered in the AI literature under the term "cognitive architecture"

3. What can semiotics contribute to the effective coordination of multiple agents, both human and artificial? This brings in the concept of "social". I haven't found a key term for this application. In cognitive science this is called "extended cognition", in AI this is "multi-agent systems", in engineering this is "cyber-physical-social systems", etc. Although this subject was anticipated by Peirce under the category "rhetoric", I have not encountered as much development within semiotics. In contrast, Dewey's work, less explciitly semiotic, has served as the basis for studies in  

From the viewpoint of biosemiotics, "thirdness" co-emerges with life. Life may emerge from a pre-existing "physical thirdness," perhaps in the form of information? The process of evolution leads to "semiotic scaffolding," with countless evolutionary stages of emergence. From this viewpoint, cognition is a late development of this process. How revolutionary cognition is depends upon the writer. 

Pattee argues that the emergence of cognition/language allows for open-ended evolution in a similar way that the genetic code did, and is on the same order of importance. From this point of view, technical semiotic systems may not need to emulate all aspects of human cognition and the ambition of "cognitive architecture" to develop a model of cognition that can be used for both engineering and scientific purposes may be misguided. The minimum components of what Peirce called "scientific intelligence" requires an ability to learn from experience but not necessarily include all of the accidental feature of the human mind/brain. I'm not sure that I'm being entirely fair to Pattee here, and perhaps attributing this gap between life and mind should be attributed to Kant.

Terrence Deacon's article *How Molecules Became Signs* [@deacon:2021:how] seems to provide a direct rebuttal to Pattee's claim that molecular processes do not have interpretants and that the Peircean frame is not directly relevant.

# Semiotic scaffolding

My previous (casual) readings within the self-identified "cognitive semiotics" appeared to be on the Kantian side. But several biosemiotic authors have tried to bridge this gap. Hoffmeyer's work on semiotic scaffolding [@hoffmeyer:2015:semiotic]. Sharov's work on agency. Claudio Paolucci has a book entitled "Cognitive Semiotics" that takes a "Peircean" view, according to the abstract, and probably is in this same tradition. 

Hoffmeyer's paper quotes from Paul Bains' book *The Primacy of Semiosis," [@bain:2006:primacy], which develops the "ontological relation" argument of Poinsot and links it to Peirce, Deleuze and other authors. Should be on my reading list.

> In the Peircean view language is just one very peculiar sign system among so many others, and the sign is a much more general phenomenon, namely a particular kind of triadic relation.

Does this formulation veer into monism? Although semiotics systems are linked through a "possibility space", this does not imply that real emergence leading to a qualitiative difference between "cognition" and "DNA" has not taken place. Pattee thought that the genetic code did not have interpretants, and that this was a real qualitative difference. (I'm not sure if Pattee ever explicitly locates the emergence of "cognition" - see note above).

> Enough is it to consider the agency of living beings, i.e., their capacity for end-directed activity, agency, is such a deep foundational property of life that it seems meaningless to explain it away (usually through natural selection types of arguments). Somehow biology must come to terms with agency as real (ontologically). (p. 5)

> A final cause is simply the general form of any process that tends toward an end state (a finale). An example of a natural law that exhibits this form of a final causation is the second law of thermodynamics, often called the "entropy law".

Identifying entropy as negative information allows this to be called the "information law." Hoffmeyer cites another book *Incomplete Nature* by Terrence Deacon. (This paper is worth reading just for these book recommendations). 

> I shall suggest that we see semiosis, emotion, and experiential life as a graded series where semiosis is a fundamental characteristic of life as such ... semiosis, emotion, and experiences are not thought to be essentially different categories, but rather to be a succession of more and more sophisticated elaborations of the same basic theme of teleodynamic existence. (p. 11)

> biosemiotics is needed precisely in order "to make explicit those assumptions imported into biology by such unanalyzed teleological concepts as function, adaptation, information, code, signal, cue, etc., and to provide a theoretical grounding for these concepts" (p. 15, quoting (Kull and Deacon, 2019 [@kull:2009:theses]))

> Peirce already understood the fundamental dynamics underneath this process, namely that "externalized signs are not mere supportive devices; instead, they undertake tasks which simply could not be performed by the brain alone" (Cobley and Stjernfelt 2015)

# Universal grammar and semiotic constraints

Deacon was referenced by Hoffmeyer's article. His book *Incomplete Nature* is now on my reading list. He has develo

In the article *Universal Grammar and Semiotic Constraints* [@deacon:2020:universal], Deacon attempts to map a middle way between symbolic and neural conceptions of the origins of *universals* (i.e. regularities) in language, of which *universal grammar* as postulated by Chomsky is a prime example. 

> The main goal of this essay will be to explain what I mean by ‘semiotic constraints’, give an account of the sense in which they must be prior to language and yet not strictly speaking innate, and finally hint at how they may influence the emergence of universals of language structure.

This article was written long before the "transformer revolution" and thus is not formulated 

Deacon develops the analogy between universals in mathematics and language. Constraints on mathematical language to describe prime numbers appear because of constraints introduced by the problem of quantity. Prime numbers, as the interaction of addition and multiplication, have a special place. 

> The assignment of any one token can be entirely unconstrained by physical details, but only if a highly constrained mapping between the domains as a whole can be identified with respect to it.

Functorial mappings are highly constrained. Given the example of prime numbers, perhaps a monoidal functor. Are there other constraints that are not functorial?

Deacon develops the meaning of the term *symbol* as it has developed in the humanities and computational science. These categories seem similar to the "distributed" and "compositional" ideas in DisCoCat.

Deacon develops the idea that there is a tradeoff between ease of production and interpretation between icons and symbols. Icons can be hard to produce but are easy to identify, while symbols can be easy to produce but take a more extensive "pre-production" of an interpretant.

## Semiotics and systems

This is my version of chicken and egg. I've been "paralyzed" by the question in that I've gone back and forth between the communities for quite a while. Although "cybersemiotics" is an explicit attempt to combine the two "doctrines", I've never been comfortable with Brier's writing. This could be a me problem. These two ideas interact strongly in the concept of "measurement systems" and this could be a valuable place to reconcile the two ideas.

Using Nic's idea that an academic subject is the community around it, the systems community seems more practically focused, perhaps because it grew out of engineering. Much of systems theory is built upon "signals", essentially a notion of "natural sign" and often identified with information. Definitions of information such as Bateson's "difference that makes a difference" have an explicitly semiotic flavor. Deacon develops the notion of "final cause" in a semiotic way that reminded me of Short's development.

Semiotics grew out of logic and was "naturalized" in biosemiotics, but I haven't seen a lot of engineering applications. So for engineering applications, it might be better to expand the notion of "signal" within systems to create "semiotic systems". This also fits within the Umbarto Eco tradition, developed within the book "Cognitive Semiotics", reviewed above. 

The SEBoK defines [systems science](https://sebokwiki.org/wiki/Systems_Science) as:

> an interdisciplinary field of science that studies the nature of complex systems in nature, society, and engineering.

I'd probably tweak this to use "technology" rather than "engineering" as a better fit for measurement systems. I like the use of "nature" rather than "physics", despite the common root, because the scope of *natural systems* usually includes the notion of a biological system.